# Scheduler è¯¦è§£

vLLMçš„Scheduleræ˜¯æ•´ä¸ªç³»ç»Ÿçš„"å¤§è„‘"ï¼Œè´Ÿè´£åè°ƒè¯·æ±‚è°ƒåº¦å’ŒKV cacheç®¡ç†ã€‚å®ƒä¸ä»…å†³å®šå“ªäº›è¯·æ±‚åœ¨ä½•æ—¶æ‰§è¡Œï¼Œè¿˜ç®¡ç†ç€æ•´ä¸ªç³»ç»Ÿçš„å†…å­˜åˆ†é…å’Œå›æ”¶ã€‚

## 1. Scheduler æ¶æ„æ¦‚è§ˆ

### 1.1 æ ¸å¿ƒèŒè´£

**è¯·æ±‚ç®¡ç†**ï¼š
- ç»´æŠ¤ä¸‰ä¸ªé˜Ÿåˆ—ï¼šwaiting(ç­‰å¾…), running(è¿è¡Œ), swapped(æ¢å‡º)
- æ ¹æ®èµ„æºå¯ç”¨æ€§è°ƒåº¦è¯·æ±‚
- å¤„ç†è¯·æ±‚ä¼˜å…ˆçº§å’ŒæŠ¢å ç­–ç•¥

**KV Cacheç®¡ç†**ï¼š
- é€šè¿‡Block Manageråˆ†é…å’Œé‡Šæ”¾GPU/CPUå†…å­˜å—
- å¤„ç†å†…å­˜swapæ“ä½œï¼ˆGPU â†” CPUï¼‰
- å®ç°prefix cachingå’Œblockå¤ç”¨
- ç®¡ç†å†…å­˜ç¢ç‰‡å’Œåƒåœ¾å›æ”¶

### 1.2 å…³é”®ç»„ä»¶

```
Scheduler
â”œâ”€â”€ Request Queues (è¯·æ±‚é˜Ÿåˆ—)
â”‚   â”œâ”€â”€ waiting: æ–°è¯·æ±‚å’Œè¢«æŠ¢å çš„è¯·æ±‚
â”‚   â”œâ”€â”€ running: æ­£åœ¨å¤„ç†çš„è¯·æ±‚ 
â”‚   â””â”€â”€ swapped: è¢«æ¢å‡ºåˆ°CPUçš„è¯·æ±‚
â”œâ”€â”€ Block Manager (å†…å­˜å—ç®¡ç†å™¨)
â”‚   â”œâ”€â”€ GPU Block Pool: GPUå†…å­˜å—æ± 
â”‚   â”œâ”€â”€ CPU Block Pool: CPUå†…å­˜å—æ± 
â”‚   â””â”€â”€ Block Tables: æ¯ä¸ªåºåˆ—çš„å—è¡¨
â””â”€â”€ Scheduling Budget (è°ƒåº¦é¢„ç®—)
    â”œâ”€â”€ token_budget: æœ¬æ¬¡å¯å¤„ç†çš„tokenæ•°
    â””â”€â”€ max_num_seqs: æœ€å¤§åºåˆ—æ•°
```

## 2. è°ƒåº¦å†³ç­–æµç¨‹

### 2.1 schedule() æ–¹æ³•æ ¸å¿ƒæµç¨‹

```python
def schedule() -> Tuple[SequenceGroupMetadata, SchedulerOutputs, bool]:
    # 1. è°ƒåº¦è¿è¡Œä¸­çš„è¯·æ±‚ (decodeé˜¶æ®µ)
    running_scheduled = self._schedule_running(budget, curr_loras)
    
    # 2. è°ƒåº¦è¢«æ¢å‡ºçš„è¯·æ±‚ (swap in)
    swapped_scheduled = self._schedule_swapped(budget, curr_loras)
    
    # 3. è°ƒåº¦ç­‰å¾…ä¸­çš„è¯·æ±‚ (prefillé˜¶æ®µ)
    prefill_scheduled = self._schedule_prefills(budget, curr_loras)
    
    # 4. æ„å»ºæœ€ç»ˆçš„è°ƒåº¦è¾“å‡º
    return build_scheduler_outputs(...)
```

### 2.2 è°ƒåº¦ç­–ç•¥

#### **Runningé˜Ÿåˆ—è°ƒåº¦**
- **ä¼˜å…ˆçº§**ï¼šRunning > Swapped > Waiting
- **èµ„æºæ£€æŸ¥**ï¼šéªŒè¯æ˜¯å¦æœ‰è¶³å¤Ÿçš„KV cacheç©ºé—´ç»§ç»­ç”Ÿæˆ
- **æŠ¢å ç­–ç•¥**ï¼šèµ„æºä¸è¶³æ—¶å¯èƒ½è¢«æ¢å‡ºæˆ–é‡æ–°è®¡ç®—

#### **Swappedé˜Ÿåˆ—è°ƒåº¦**  
- **æ¢å…¥æ¡ä»¶**ï¼šGPUæœ‰è¶³å¤Ÿç©ºé—´ä¸”ç¬¦åˆwatermarkè¦æ±‚
- **å—å¤åˆ¶**ï¼šCPU â†’ GPU çš„å†…å­˜å—è¿ç§»

#### **Waitingé˜Ÿåˆ—è°ƒåº¦**
- **æ–°è¯·æ±‚å¤„ç†**ï¼šåˆ†é…åˆå§‹KV cacheç©ºé—´
- **Chunked Prefill**ï¼šå¤§promptåˆ†å—å¤„ç†

## 3. KV Cache ç®¡ç†æœºåˆ¶

### 3.1 Block Manager æ¶æ„

```
Block Manager
â”œâ”€â”€ Block Allocator (åˆ†é…å™¨)
â”‚   â”œâ”€â”€ GPU Block Pool
â”‚   â”œâ”€â”€ CPU Block Pool  
â”‚   â””â”€â”€ Block Evictor (é©±é€å™¨)
â”œâ”€â”€ Block Tables (å—è¡¨)
â”‚   â””â”€â”€ seq_id -> [block_0, block_1, ...]
â””â”€â”€ Prefix Cache (å‰ç¼€ç¼“å­˜)
    â””â”€â”€ hash -> cached_block
```

### 3.2 å†…å­˜åˆ†é…æµç¨‹

#### **æ–°è¯·æ±‚åˆ†é…**ï¼š
1. **è¯„ä¼°éœ€æ±‚**ï¼šè®¡ç®—promptéœ€è¦çš„blockæ•°é‡
2. **æ£€æŸ¥å¯ç”¨æ€§**ï¼š`can_allocate()` æ£€æŸ¥GPUå†…å­˜æ˜¯å¦å……è¶³
3. **åˆ†é…blocks**ï¼šä»free poolä¸­åˆ†é…æ‰€éœ€blocks
4. **å»ºç«‹æ˜ å°„**ï¼šåˆ›å»ºé€»è¾‘blockåˆ°ç‰©ç†blockçš„æ˜ å°„

#### **ç»§ç»­ç”Ÿæˆ**ï¼š
1. **æ£€æŸ¥ç©ºé—´**ï¼š`can_append_slots()` éªŒè¯æ˜¯å¦å¯ä»¥ç»§ç»­
2. **è¿½åŠ slots**ï¼šä¸ºæ–°tokenåˆ†é…ç©ºé—´
3. **Copy-on-Write**ï¼šéœ€è¦æ—¶å¤åˆ¶blockä»¥æ”¯æŒbeam search

### 3.3 Swap æœºåˆ¶

#### **Swap Out (GPU â†’ CPU)**ï¼š
```python
def swap_out(seq_group):
    # 1. æ£€æŸ¥CPUæ˜¯å¦æœ‰è¶³å¤Ÿç©ºé—´
    if not can_swap_out(seq_group):
        raise MemoryError("CPUç©ºé—´ä¸è¶³")
    
    # 2. æ‰§è¡Œblockè¿ç§»
    gpu_blocks = get_gpu_blocks(seq_group)
    cpu_blocks = allocate_cpu_blocks(len(gpu_blocks))
    copy_blocks(gpu_blocks, cpu_blocks)
    
    # 3. æ›´æ–°æ˜ å°„è¡¨
    update_block_mapping(gpu_blocks, cpu_blocks)
    
    # 4. é‡Šæ”¾GPUå†…å­˜
    free_gpu_blocks(gpu_blocks)
```

#### **Swap In (CPU â†’ GPU)**ï¼š
```python
def swap_in(seq_group):
    # 1. æ£€æŸ¥GPUç©ºé—´
    if not can_swap_in(seq_group):
        return AllocStatus.LATER
    
    # 2. åˆ†é…GPU blocks
    gpu_blocks = allocate_gpu_blocks(required_size)
    
    # 3. ä»CPUå¤åˆ¶æ•°æ®
    cpu_blocks = get_cpu_blocks(seq_group)
    copy_blocks(cpu_blocks, gpu_blocks)
    
    # 4. æ›´æ–°çŠ¶æ€
    update_seq_status(seq_group, RUNNING)
```

## 4. è°ƒåº¦ç®—æ³•è¯¦è§£

### 4.1 èµ„æºé¢„ç®—è®¡ç®—

```python
class SchedulingBudget:
    token_budget: int        # æœ¬æ‰¹æ¬¡æœ€å¤§tokenæ•°
    max_num_seqs: int       # æœ€å¤§åºåˆ—æ•°
    num_batched_tokens: int # å·²è°ƒåº¦tokenæ•°
    num_curr_seqs: int      # å½“å‰åºåˆ—æ•°
    
    def can_schedule(self, num_new_tokens, num_new_seqs):
        return (self.num_batched_tokens + num_new_tokens <= self.token_budget
                and self.num_curr_seqs + num_new_seqs <= self.max_num_seqs)
```

### 4.2 æŠ¢å ç­–ç•¥

#### **æŠ¢å è§¦å‘æ¡ä»¶**ï¼š
- GPUå†…å­˜ä¸è¶³
- æœ‰æ›´é«˜ä¼˜å…ˆçº§è¯·æ±‚
- è¾¾åˆ°èµ„æºé™åˆ¶

#### **æŠ¢å æ¨¡å¼**ï¼š
1. **Recomputeæ¨¡å¼**ï¼šä¸¢å¼ƒKV cacheï¼Œé‡æ–°è®¡ç®—
2. **Swapæ¨¡å¼**ï¼šè¿ç§»åˆ°CPUå†…å­˜

```python
def _preempt(self, seq_group, blocks_to_swap_out):
    if seq_group.has_multiple_seqs():
        # beam searchç­‰å¤šåºåˆ—æƒ…å†µä½¿ç”¨swap
        return self._preempt_by_swap(seq_group, blocks_to_swap_out)
    else:
        # å•åºåˆ—ä½¿ç”¨recomputeï¼Œå¼€é”€æ›´å°
        return self._preempt_by_recompute(seq_group)
```

### 4.3 Chunked Prefill

å¯¹äºé•¿promptï¼ŒvLLMä½¿ç”¨åˆ†å—å¤„ç†ç­–ç•¥ï¼š

```python
def _schedule_chunked_prefill():
    # 1. é™åˆ¶å¹¶å‘é•¿prefillæ•°é‡
    max_long_prefills = scheduler_config.max_long_partial_prefills
    
    # 2. ä¸ºé•¿promptåˆ†é…tokené¢„ç®—
    chunk_size = min(prompt_length, available_budget)
    
    # 3. å…è®¸çŸ­è¯·æ±‚æ’é˜Ÿ
    if prompt_length < long_prefill_threshold:
        schedule_immediately()
```

## 5. æ€§èƒ½ä¼˜åŒ–æœºåˆ¶

### 5.1 Prefix Caching

**ç¼“å­˜ç­–ç•¥**ï¼š
- ç›¸åŒprefixçš„è¯·æ±‚å…±äº«KV cache blocks
- ä½¿ç”¨hashå€¼å¿«é€ŸåŒ¹é…
- LRUé©±é€ç­–ç•¥

**å®ç°ç»†èŠ‚**ï¼š
```python
def allocate_with_prefix_cache(token_ids):
    # 1. è®¡ç®—prefix hash
    prefix_hash = compute_hash(token_ids)
    
    # 2. æŸ¥æ‰¾ç¼“å­˜
    cached_blocks = find_cached_prefix(prefix_hash)
    
    # 3. å¤ç”¨ç¼“å­˜blocks + åˆ†é…æ–°blocks
    return cached_blocks + allocate_new_blocks(remaining_tokens)
```

### 5.2 Block å¤ç”¨æœºåˆ¶

**Copy-on-Write**ï¼š
- å¤šä¸ªåºåˆ—å¯å…±äº«åªè¯»blocks
- å†™æ“ä½œæ—¶è‡ªåŠ¨å¤åˆ¶block
- å‡å°‘å†…å­˜å ç”¨

**Blockåˆå¹¶**ï¼š
- ç›¸åŒå†…å®¹çš„blocksè‡ªåŠ¨åˆå¹¶
- å¼•ç”¨è®¡æ•°ç®¡ç†ç”Ÿå‘½å‘¨æœŸ

### 5.3 Watermarkç­–ç•¥

```python
def check_watermark(required_blocks):
    free_blocks = get_num_free_gpu_blocks()
    watermark_blocks = total_blocks * watermark_ratio
    
    # ä¿ç•™watermarké¿å…é¢‘ç¹æ¢å‡º
    return free_blocks - required_blocks >= watermark_blocks
```

## 6. è°ƒåº¦è¾“å‡ºç»“æ„

### 6.1 SchedulerOutputs

```python
@dataclass
class SchedulerOutputs:
    scheduled_seq_groups: List[ScheduledSequenceGroup]  # æœ¬æ¬¡è°ƒåº¦çš„è¯·æ±‚
    num_prefill_groups: int                             # prefillè¯·æ±‚æ•°
    num_batched_tokens: int                             # æ€»tokenæ•°
    blocks_to_swap_in: List[Tuple[int, int]]           # éœ€è¦swap inçš„blocks
    blocks_to_swap_out: List[Tuple[int, int]]          # éœ€è¦swap outçš„blocks  
    blocks_to_copy: List[Tuple[int, int]]              # éœ€è¦å¤åˆ¶çš„blocks
    ignored_seq_groups: List[SequenceGroup]            # è¢«å¿½ç•¥çš„è¯·æ±‚
    num_lookahead_slots: int                           # æ¨æµ‹è§£ç slots
    running_queue_size: int                            # è¿è¡Œé˜Ÿåˆ—å¤§å°
    preempted: int                                     # è¢«æŠ¢å çš„è¯·æ±‚æ•°
```

### 6.2 æ‰§è¡ŒæŒ‡ä»¤

Schedulerçš„è¾“å‡ºç›´æ¥æŒ‡å¯¼workerçš„æ“ä½œï¼š
- **scheduled_seq_groups**: éœ€è¦æ‰§è¡Œå‰å‘ä¼ æ’­çš„è¯·æ±‚
- **blocks_to_swap_***: å†…å­˜ç®¡ç†æ“ä½œæŒ‡ä»¤
- **blocks_to_copy**: Copy-on-Writeæ“ä½œæŒ‡ä»¤

## 7. é”™è¯¯å¤„ç†å’Œæ¢å¤

### 7.1 å†…å­˜ä¸è¶³å¤„ç†

```python
def handle_oom():
    # 1. è§¦å‘æŠ¢å 
    preempted_groups = preempt_lowest_priority()
    
    # 2. æ‰§è¡Œswap out
    swap_out_groups(preempted_groups)
    
    # 3. æ¸…ç†ç¢ç‰‡
    garbage_collect_blocks()
    
    # 4. é‡æ–°è°ƒåº¦
    reschedule_remaining_requests()
```

### 7.2 è°ƒåº¦å¤±è´¥æ¢å¤

- **èµ„æºç­‰å¾…**ï¼šAllocStatus.LATERï¼Œä¸‹æ¬¡è°ƒåº¦é‡è¯•
- **æ°¸ä¹…å¤±è´¥**ï¼šAllocStatus.NEVERï¼Œæ‹’ç»è¯·æ±‚
- **çŠ¶æ€å›æ»š**ï¼šè°ƒåº¦å¤±è´¥æ—¶æ¢å¤åŸå§‹çŠ¶æ€

## 8. ç›‘æ§å’Œè°ƒè¯•

### 8.1 å…³é”®æŒ‡æ ‡

```python
# å†…å­˜ä½¿ç”¨ç‡
gpu_cache_usage = 1.0 - (free_gpu_blocks / total_gpu_blocks)

# ç¼“å­˜å‘½ä¸­ç‡  
prefix_cache_hit_rate = cached_tokens / total_tokens

# é˜Ÿåˆ—é•¿åº¦
queue_lengths = {
    'waiting': len(scheduler.waiting),
    'running': len(scheduler.running), 
    'swapped': len(scheduler.swapped)
}

# æŠ¢å ç»Ÿè®¡
preemption_stats = {
    'recompute': recompute_count,
    'swap': swap_count
}
```

### 8.2 è°ƒè¯•å·¥å…·

- **Blockå¯è§†åŒ–**ï¼šæ˜¾ç¤ºblockåˆ†é…çŠ¶æ€
- **è°ƒåº¦å†³ç­–æ—¥å¿—**ï¼šè®°å½•æ¯æ¬¡è°ƒåº¦çš„å†³ç­–è¿‡ç¨‹
- **å†…å­˜æ³„æ¼æ£€æµ‹**ï¼šè¿½è¸ªæœªé‡Šæ”¾çš„blocks

## 9. æ€»ç»“

vLLMçš„Scheduleré€šè¿‡ç²¾å¯†çš„è®¾è®¡å®ç°äº†ï¼š

âœ… **é«˜æ•ˆçš„èµ„æºç®¡ç†**ï¼šåŠ¨æ€åˆ†é…å’Œå›æ”¶GPU/CPUå†…å­˜  
âœ… **æ™ºèƒ½çš„è°ƒåº¦ç­–ç•¥**ï¼šå¹³è¡¡ååé‡å’Œå»¶è¿Ÿ  
âœ… **å…ˆè¿›çš„ç¼“å­˜æœºåˆ¶**ï¼šprefix cachingå‡å°‘é‡å¤è®¡ç®—  
âœ… **çµæ´»çš„æŠ¢å æœºåˆ¶**ï¼šåº”å¯¹èµ„æºç«äº‰  
âœ… **å¯æ‰©å±•çš„æ¶æ„**ï¼šæ”¯æŒåˆ†å¸ƒå¼å’Œå¼‚æ„éƒ¨ç½²  

è¿™ç§è®¾è®¡ä½¿å¾—vLLMèƒ½å¤Ÿåœ¨æœ‰é™çš„GPUå†…å­˜ä¸‹æœåŠ¡æ›´å¤šè¯·æ±‚ï¼ŒåŒæ—¶ä¿æŒä½å»¶è¿Ÿå’Œé«˜ååé‡ã€‚

## 10. å›¾è§£

### 10.1 Schedulerè°ƒåº¦æµç¨‹å›¾

```mermaid
graph TD
    A["è¯·æ±‚åˆ°è¾¾"] --> B["Scheduler.add_seq_group()"]
    B --> C["åŠ å…¥waitingé˜Ÿåˆ—"]
    
    C --> D["Scheduler.schedule()"]
    D --> E["1. è°ƒåº¦runningé˜Ÿåˆ—"]
    D --> F["2. è°ƒåº¦swappedé˜Ÿåˆ—"] 
    D --> G["3. è°ƒåº¦waitingé˜Ÿåˆ—"]
    
    E --> E1["æ£€æŸ¥KV cacheç©ºé—´"]
    E1 --> E2{è¶³å¤Ÿç©ºé—´?}
    E2 -->|æ˜¯| E3["ç»§ç»­decode"]
    E2 -->|å¦| E4["æŠ¢å å¤„ç†"]
    
    E4 --> E5{æŠ¢å æ¨¡å¼}
    E5 -->|recompute| E6["ä¸¢å¼ƒKV cache<br/>ç§»åˆ°waiting"]
    E5 -->|swap| E7["ç§»åˆ°CPU<br/>åŠ å…¥swapped"]
    
    F --> F1["æ£€æŸ¥GPUç©ºé—´"]
    F1 --> F2{å¯ä»¥swap in?}
    F2 -->|æ˜¯| F3["CPUâ†’GPU<br/>ç§»åˆ°running"]
    F2 -->|å¦| F4["ä¿æŒswappedçŠ¶æ€"]
    
    G --> G1["åˆ†é…KV cache"]
    G1 --> G2{å†…å­˜å……è¶³?}
    G2 -->|æ˜¯| G3["å¼€å§‹prefill<br/>ç§»åˆ°running"]
    G2 -->|å¦| G4["ä¿æŒwaitingçŠ¶æ€"]
    
    E3 --> H["æ„å»ºSchedulerOutputs"]
    F3 --> H
    G3 --> H
    
    H --> I["è¿”å›è°ƒåº¦ç»“æœ"]
    I --> J["Workeræ‰§è¡Œ"]
    
    style A fill:#e1f5fe
    style B fill:#f3e5f5
    style D fill:#fff3e0
    style E fill:#e8f5e8
    style F fill:#ffebee
    style G fill:#f1f8e9
    style H fill:#fce4ec
```

### 10.2 KV Cacheç®¡ç†æ¶æ„å›¾

```mermaid
graph TD
    A["Block Manager"] --> B["GPU Block Pool"]
    A --> C["CPU Block Pool"]
    A --> D["Block Tables"]
    
    B --> B1["Free Blocks"]
    B --> B2["Allocated Blocks"]
    B --> B3["Cached Blocks"]
    
    C --> C1["Swap Space"]
    C --> C2["Free CPU Blocks"]
    
    D --> D1["seq_id â†’ block_table"]
    D1 --> D2["[block_0, block_1, ...]"]
    
    E["æ–°è¯·æ±‚"] --> F["can_allocate()"]
    F --> F1{GPUå†…å­˜è¶³å¤Ÿ?}
    F1 -->|æ˜¯| F2["allocate()"]
    F1 -->|å¦| F3["AllocStatus.LATER"]
    
    F2 --> G["ä»Free Poolåˆ†é…blocks"]
    G --> H["å»ºç«‹block_tableæ˜ å°„"]
    H --> I["æ›´æ–°Allocated Blocks"]
    
    J["ç»§ç»­ç”Ÿæˆ"] --> K["can_append_slots()"]
    K --> K1{æœ‰è¶³å¤Ÿç©ºé—´?}
    K1 -->|æ˜¯| K2["append_slots()"]
    K1 -->|å¦| K3["è§¦å‘æŠ¢å "]
    
    K2 --> L["åˆ†é…æ–°slots"]
    L --> M["Copy-on-Writeå¤„ç†"]
    
    N["å†…å­˜å‹åŠ›"] --> O["swap_out()"]
    O --> P["GPU â†’ CPUè¿ç§»"]
    P --> Q["é‡Šæ”¾GPU blocks"]
    Q --> R["æ›´æ–°blockæ˜ å°„"]
    
    S["æ¢å¤è¯·æ±‚"] --> T["swap_in()"]
    T --> U["CPU â†’ GPUè¿ç§»"]
    U --> V["åˆ†é…GPU blocks"]
    
    W["Prefix Cache"] --> X["hash â†’ cached_block"]
    X --> Y["LRUé©±é€ç­–ç•¥"]
    Y --> Z["å¼•ç”¨è®¡æ•°ç®¡ç†"]
    
    style A fill:#e1f5fe
    style B fill:#e8f5e8
    style C fill:#ffebee
    style D fill:#fff3e0
    style W fill:#f3e5f5
```

### 10.3 è°ƒåº¦æ—¶åºå›¾

```mermaid
sequenceDiagram
    participant Engine as LLMEngine
    participant Scheduler as Scheduler
    participant BlockMgr as BlockManager
    participant GPU as GPU Memory
    participant CPU as CPU Memory
    
    Note over Engine,CPU: è¯·æ±‚åˆ°è¾¾å’Œè°ƒåº¦
    Engine->>Scheduler: add_seq_group(request)
    Scheduler->>Scheduler: åŠ å…¥waitingé˜Ÿåˆ—
    
    Note over Engine,CPU: è°ƒåº¦å¾ªç¯å¼€å§‹
    Engine->>Scheduler: schedule()
    
    Note over Scheduler,BlockMgr: 1. å¤„ç†Runningé˜Ÿåˆ—
    Scheduler->>BlockMgr: can_append_slots(seq_group)
    BlockMgr->>GPU: æ£€æŸ¥å¯ç”¨ç©ºé—´
    GPU-->>BlockMgr: ç©ºé—´çŠ¶æ€
    
    alt ç©ºé—´å……è¶³
        BlockMgr-->>Scheduler: True
        Scheduler->>BlockMgr: append_slots()
        BlockMgr->>GPU: åˆ†é…æ–°slots
        GPU-->>BlockMgr: åˆ†é…æˆåŠŸ
    else ç©ºé—´ä¸è¶³
        BlockMgr-->>Scheduler: False
        Scheduler->>Scheduler: è§¦å‘æŠ¢å 
        
        alt Recomputeæ¨¡å¼
            Scheduler->>BlockMgr: free(seq)
            BlockMgr->>GPU: é‡Šæ”¾blocks
            Scheduler->>Scheduler: ç§»åˆ°waitingé˜Ÿåˆ—
        else Swapæ¨¡å¼
            Scheduler->>BlockMgr: swap_out(seq_group)
            BlockMgr->>CPU: æ£€æŸ¥CPUç©ºé—´
            CPU-->>BlockMgr: ç©ºé—´å¯ç”¨
            BlockMgr->>GPU: å¤åˆ¶æ•°æ®åˆ°CPU
            BlockMgr->>CPU: ä¿å­˜blocks
            BlockMgr->>GPU: é‡Šæ”¾GPU blocks
            Scheduler->>Scheduler: ç§»åˆ°swappedé˜Ÿåˆ—
        end
    end
    
    Note over Scheduler,BlockMgr: 2. å¤„ç†Swappedé˜Ÿåˆ—
    Scheduler->>BlockMgr: can_swap_in(seq_group)
    BlockMgr->>GPU: æ£€æŸ¥watermark
    
    alt å¯ä»¥swap in
        GPU-->>BlockMgr: ç©ºé—´å……è¶³
        BlockMgr-->>Scheduler: AllocStatus.OK
        Scheduler->>BlockMgr: swap_in(seq_group)
        BlockMgr->>GPU: åˆ†é…GPU blocks
        BlockMgr->>CPU: ä»CPUå¤åˆ¶æ•°æ®
        BlockMgr->>GPU: æ¢å¤KV cache
        Scheduler->>Scheduler: ç§»åˆ°runningé˜Ÿåˆ—
    else ç©ºé—´ä¸è¶³
        GPU-->>BlockMgr: ç©ºé—´ä¸è¶³
        BlockMgr-->>Scheduler: AllocStatus.LATER
        Scheduler->>Scheduler: ä¿æŒswappedçŠ¶æ€
    end
    
    Note over Scheduler,BlockMgr: 3. å¤„ç†Waitingé˜Ÿåˆ—
    Scheduler->>BlockMgr: can_allocate(seq_group)
    BlockMgr->>GPU: è®¡ç®—æ‰€éœ€blocks
    BlockMgr->>GPU: æ£€æŸ¥å¯ç”¨ç©ºé—´
    
    alt ç©ºé—´å……è¶³
        GPU-->>BlockMgr: ç©ºé—´å……è¶³
        BlockMgr-->>Scheduler: AllocStatus.OK
        Scheduler->>BlockMgr: allocate(seq_group)
        
        alt å¯ç”¨Prefix Cache
            BlockMgr->>BlockMgr: è®¡ç®—prefix hash
            BlockMgr->>BlockMgr: æŸ¥æ‰¾cached blocks
            BlockMgr->>GPU: å¤ç”¨ç¼“å­˜+åˆ†é…æ–°blocks
        else æ™®é€šåˆ†é…
            BlockMgr->>GPU: åˆ†é…æ‰€éœ€blocks
        end
        
        BlockMgr->>BlockMgr: å»ºç«‹block_tableæ˜ å°„
        Scheduler->>Scheduler: ç§»åˆ°runningé˜Ÿåˆ—
    else ç©ºé—´ä¸è¶³
        GPU-->>BlockMgr: ç©ºé—´ä¸è¶³
        BlockMgr-->>Scheduler: AllocStatus.LATER
        Scheduler->>Scheduler: ä¿æŒwaitingçŠ¶æ€
    end
    
    Note over Scheduler,CPU: æ„å»ºè°ƒåº¦è¾“å‡º
    Scheduler->>Scheduler: æ„å»ºSchedulerOutputs
    Scheduler-->>Engine: è¿”å›è°ƒåº¦ç»“æœ
    
    Note over Engine,CPU: å†…å­˜ç®¡ç†æŒ‡ä»¤
    Engine->>Engine: å¤„ç†blocks_to_swap_in
    Engine->>Engine: å¤„ç†blocks_to_swap_out
    Engine->>Engine: å¤„ç†blocks_to_copy
```

## 11. Schedulerä¸Engineçš„åä½œ

ä»å‰é¢çš„`execute_model`åˆ†æå’Œè¿™é‡Œçš„scheduleråˆ†æï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¸¤è€…çš„ç´§å¯†åä½œï¼š

### 11.1 è°ƒç”¨å…³ç³»

```
LLMEngine.step()
â”œâ”€â”€ scheduler.schedule()          # ğŸ§  è°ƒåº¦å†³ç­–
â”‚   â”œâ”€â”€ æ£€æŸ¥èµ„æºå¯ç”¨æ€§
â”‚   â”œâ”€â”€ åˆ†é…/å›æ”¶KV cache
â”‚   â””â”€â”€ è¿”å›SchedulerOutputs
â”œâ”€â”€ model_executor.execute_model() # âš¡ æ¨¡å‹æ‰§è¡Œ  
â”‚   â”œâ”€â”€ å¤„ç†swapæ“ä½œ
â”‚   â”œâ”€â”€ æ‰§è¡Œæ¨¡å‹å‰å‘ä¼ æ’­
â”‚   â””â”€â”€ è¿”å›SamplerOutput
â””â”€â”€ å¤„ç†è¾“å‡ºå¹¶æ›´æ–°çŠ¶æ€        # ğŸ“¤ ç»“æœå¤„ç†
```

### 11.2 æ•°æ®æµè½¬

1. **Schedulerè¾“å‡º â†’ Engineè¾“å…¥**ï¼š
   - `scheduled_seq_groups` â†’ æ¨¡å‹è¦å¤„ç†çš„è¯·æ±‚
   - `blocks_to_swap_*` â†’ GPU/CPUå†…å­˜æ“ä½œæŒ‡ä»¤
   - `blocks_to_copy` â†’ Copy-on-Writeæ“ä½œ

2. **Engineè¾“å‡º â†’ Schedulerè¾“å…¥**ï¼š
   - ç”Ÿæˆçš„æ–°tokens â†’ æ›´æ–°åºåˆ—çŠ¶æ€
   - å®Œæˆçš„è¯·æ±‚ â†’ é‡Šæ”¾KV cache
   - é”™è¯¯çŠ¶æ€ â†’ è§¦å‘é‡è°ƒåº¦

### 11.3 æ ¸å¿ƒè®¾è®¡åŸåˆ™

**ğŸ¯ è´£ä»»åˆ†ç¦»**ï¼š
- Schedulerè´Ÿè´£"è°ƒåº¦ä»€ä¹ˆ"
- Engineè´Ÿè´£"å¦‚ä½•æ‰§è¡Œ"

**ğŸ’¾ èµ„æºç®¡ç†**ï¼š
- Schedulerç»Ÿä¸€ç®¡ç†KV cacheåˆ†é…
- EngineæŒ‰æŒ‡ä»¤æ‰§è¡Œå†…å­˜æ“ä½œ

**âš¡ æ€§èƒ½ä¼˜åŒ–**ï¼š
- Scheduleré¢„æµ‹å’Œé¢„åˆ†é…èµ„æº
- Engineæ‰¹å¤„ç†å’Œå¼‚æ­¥æ‰§è¡Œ

## 12. æ€»ç»“

vLLMçš„Scheduleræ˜¯ä¸€ä¸ªé«˜åº¦ä¼˜åŒ–çš„èµ„æºç®¡ç†å’Œè°ƒåº¦ç³»ç»Ÿï¼š

ğŸ¯ **æ ¸å¿ƒä»·å€¼**ï¼š
- **æ™ºèƒ½è°ƒåº¦**ï¼šåŠ¨æ€å¹³è¡¡ååé‡å’Œå»¶è¿Ÿ
- **å†…å­˜ä¼˜åŒ–**ï¼šæœ€å¤§åŒ–GPUå†…å­˜åˆ©ç”¨ç‡  
- **ç¼“å­˜åŠ é€Ÿ**ï¼šprefix cachingå‡å°‘é‡å¤è®¡ç®—
- **å¼¹æ€§æ‰©å±•**ï¼šæ”¯æŒCPU swapå’Œåˆ†å¸ƒå¼éƒ¨ç½²

âš¡ **è®¾è®¡äº®ç‚¹**ï¼š
- **åˆ†å±‚é˜Ÿåˆ—**ï¼šwaiting/running/swappedä¸‰çº§ç®¡ç†
- **æŠ¢å æœºåˆ¶**ï¼šä¼˜é›…å¤„ç†èµ„æºç«äº‰
- **å—ç®¡ç†**ï¼šç»†ç²’åº¦çš„å†…å­˜åˆ†é…å’Œå›æ”¶
- **é¢„ç®—æ§åˆ¶**ï¼šç²¾ç¡®çš„èµ„æºä½¿ç”¨é™åˆ¶

ğŸš€ **æ€§èƒ½ä¼˜åŠ¿**ï¼š
- **é«˜ååé‡**ï¼šæ‰¹å¤„ç†å’Œè¿ç»­batching
- **ä½å»¶è¿Ÿ**ï¼šæ™ºèƒ½è°ƒåº¦å’Œå†…å­˜ç®¡ç†
- **é«˜åˆ©ç”¨ç‡**ï¼šåŠ¨æ€èµ„æºåˆ†é…å’Œå…±äº«
- **å¼ºæ‰©å±•æ€§**ï¼šæ”¯æŒå¤§è§„æ¨¡å¹¶å‘æœåŠ¡

é€šè¿‡æ·±å…¥ç†è§£Schedulerçš„å·¥ä½œæœºåˆ¶ï¼Œæˆ‘ä»¬å¯ä»¥æ›´å¥½åœ°é…ç½®å’Œä¼˜åŒ–vLLMç³»ç»Ÿï¼Œå®ç°é«˜æ•ˆçš„å¤§è¯­è¨€æ¨¡å‹æ¨ç†æœåŠ¡ã€‚ 